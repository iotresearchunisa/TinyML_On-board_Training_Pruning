
# Energy saving and continuous learning in resource-constrained MCUs by on-board training and pruning

## Abstract
The field of Tiny Machine Learning has attracted significant research interest in the Internet of Things and edge computing contexts. In this context, continuous on-board learning has emerged as an innovative research topic. However, the high resource consumption resulting from the intensive and prolonged use of neural networks to make inference can pose a significant challenge for tiny devices, particularly due to stringent constraints on memory and power consumption. This paper is pioneering in its approach, offering a comprehensive and practical implementation of an on-board pruning procedure. This procedure is designed to reduce model latency and power consumption without the need for data transmission to a central server.The pruning process is integrated into the incremental on-board training, directly on memory-constrained devices such as MCUs with less than 256 KB of RAM, without the requirement of custom hardware. An experimental evaluation on real devices is provided to assist machine learning developers in determining the optimal balance between model performance and energy efficiency.

## Code Request
The code will be made public as soon as the article is published. In the meantime, you can request access by emailing [mficco@unisa.it](mailto:mficco@unisa.it).

## Authors
- [@Pietro Fusco](https://docenti.unisa.it/064613/home)
- [@Gennaro Pio Rimoli](https://scholar.google.com/citations?user=PcvfK5MAAAAJ&hl=it&oi=ao)
- [@Antonio Guerriero](https://www.docenti.unina.it/#!/professor/414e544f4e494f47554552524945524f4752524e544e39324d3036483933314c/riferimenti)
- [@Massimo Ficco](https://docenti.unisa.it/058291/home)


## Acknowledgements
The work is part of the research activities realized within the projects FLEGREA (CUP. E53D23007950001), Bando PRIN 2022, as well as SERICS (PE00000014) under the NRRP MUR program funded by the EU - NGEU.
